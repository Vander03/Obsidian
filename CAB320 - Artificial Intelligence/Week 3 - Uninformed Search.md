![[Pasted image 20250316153129.png|500]]
## 1 Planning
The agent devises a description of the states and actions necessary to reach the goal
## 2 Search Problems
A search problem is defined as follows:
- A set of initial states that the environment can be in, called **state space**
- The initial stage the agent starts in
- A set of one or more goal states. There can be alternative goal states and also a goal can apply to many states
- The actions available to the agent
- The transition model which describes what the result of each action is (travelling to a city)
- The action cost function gives the numeric cost of applying the function to the state to reach another state
![[Pasted image 20250315194202.png|600]]

### 2.1 Vacuum world state space example
![[Pasted image 20250315194433.png]]

### 2.2 Sokoban Puzzle (8-Puzzle)



## 3 Uninformed Search Methods
### 3.1 Tree Search Algorithms
The basic idea of tree search algorithms is to allow for an offline, simulated exploration of state space by mapping successors of already explored states.
NOTE: **states** are representation of the environment configuration, n**odes contain the state**, parent, children etc. 

![[Pasted image 20250316132914.png]]

For example: exploring all the possible routes to get to a town:
![[Pasted image 20250316132957.png|400]]![[Pasted image 20250316133010.png|400]]

### 3.2 Search Strategies
Strategies are defined by picking an order of operation, and are evaluated against the following:
- Completeness - is the algorithm guaranteed to find a solution when there is one
- Cost optimality - does it find a solution with the lowest path cost for all solutions
- Time complexity - how long does it take to find a solution (measured in time or states considered)
- Space complexity - how much memory is needed to perform the search

Time and space complexity are measured in terms of:
- maximum branching factor
- depth of least cost solution
- maximum depth of the state space

#### 3.2.1 Breadth-First Search (O($b^d$))
![[Pasted image 20250316140555.png]]
Suitable when all actions have the same cost. It expands the first node, then all its nodes, etc.
The function can be made more efficient through the use of a FIFO queue instead of priority, and will give us the correct order of nodes, in the sense that newer nodes will go to the back of the list and older nodes (parents) will remain at the start and thus get expanded first.

We can also implement an **early goal test** that tests if the node is a goal as soon as its generated.

![[Pasted image 20250316140609.png]]

#### 3.2.2 Djikstra's Algorithm (Uniform Cost Search) ($O(b^{[C^*/\epsilon]})$ 
(with C being the cost of the optimal solution and $\epsilon$ being the lower bound on the cost of each action))

Goal is to expand the cheapest unexpanded node. It finds the cheapest current path by going the cheapest option first, and then once that has been explored it explores the next cheapest option. If the next route results in a cheaper outcome the previous route is replaced. It is ONLY checked for goal once the node is expanded, not when it is generated.

Its performance can be much worse because the algorithm can explore all the low cost options before exploring a higher cost and maybe more useful function.

Uniform cost search is complete and cost optimal.

#### 3.2.3 Depth-First Search
**Memory complexity :** $O(bm)$ 
	$b$ - branching factor
	$m$  - maximum depth of tree
**Time complexity :** $O(b^m)$
Depth-first always expands to the deepest node first. It is not cost efficient as it will return the first solution it finds. It is time efficient and complete for *finite acyclic state spaces*. Some iterations check for cycles at every new node it expands to ensure it does not get stuck in a loop. It is not complete or efficient for infinite state spaces as it will drill down to the lowest node for infinity.

Aside from its limitations it is very memory efficient as a reached table is not kept at all. It could be implemented with a LIFO queue to keep track of reached states if needed.

#### 3.2.4 Backtracking Search
Backtracking search is a variant of Depth-first and is even more memory efficient.
In backtracking, only one successor is generated at a time rather than all successors; each partially expanded node remembers which successor to generate next. In addition, successors are generated by modifying the current state description directly rather than allocating memory for a brand-new state. This reduces the memory requirements to just one state description and a path of O(m) actions; a significant savings over O(bm) states for depth-first search. With backtracking we also have the option of maintaining an efficient set data structure for the states on the current path, allowing us to check for a cyclic path in O(1) time rather than O(m). For backtracking to work, we must be able to undo each action when we backtrack. Backtracking is critical to the success of many problems with large state descriptions, such as robotic assembly.

#### 3.2.5 Depth-Limited Search
**Time complexity :** - $O(b^l)$
**Space complexity :** - $O(bl)$
Depth limited search keeps depth-first in check by specifying a depth limit ($l$), at which the notes are treated has having no successors.

The **diameter** of a graph refers to the length of the shortest path between the most distanced nodes. This value gives us a much better approximation of the depth value required.
#### 3.2.6 Iterative Deepening Search
An extension of depth-limited search is **Iterative deepening search**, which solves the issue of depth value by truing all values until a solution is found.
**Time complexity :** `solution == true ? O(b^d) : O(b^m)`


The algorithm is shown in Figure 3.12. Iterative deepening combines many of the benefits of depth-first and breadth-first search. Like depth-first search, its memory requirements are modest: O(bd) when there is a solution, or O(bm) on finite state spaces with no solution. Like breadth-first search, iterative deepening is optimal for problems where all actions have the same cost, and is complete on finite acyclic state spaces, or on any finite state space when we check nodes for cycles all the way up the path.
![[Pasted image 20250316145613.png]]
![[Pasted image 20250316152930.png]]

### 3.3 Graph Search vs Tree Search
Graph search keeps a queue of the visited nodes
![[Pasted image 20250316155929.png]]

